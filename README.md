# ⏩ Speech-Emotion-Recognition

Emotional state identification based on analysis of vocalization is a challenging subject in the field of Human-Computer Interaction (HCI). A wide range of research approaches has been used and recent research has suggested the use of deep learning algorithms. as potential alternatives to the approaches that are traditionally used in SER. The objective of this project is to utilize Deep Neural Network (DNNs) to recognise human speech emotion . First Mel – Frequency cepstral coefficient (MFCC) are extracted from raw audio data then speech features extracted were fed into DNN to train the network. The trained network was then tested onto a set of labelled emotion speech audio and the recognition rate was evaluated. Based on the accuracy rate of MFCC, number of neurons and layers are adjusted for optimization. Beyond the scope of previous researches, this project emphasize on speech based output instead of text based results. 

## → Prerequisites:
<ul>
  <li>Numpy</li>
  <li>Pandas</li>
  <li>Matplotlib</li>
  <li>Seaborn</li>
  <li>Librosa</li>
  <li>Sckit-Learn</li>
  <li>Keras</li>
</ul>

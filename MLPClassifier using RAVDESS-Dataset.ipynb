{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "from IPython.display import Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f60581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140036f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with warnings\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870225c",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileEmotion=[]\n",
    "filePath=[]\n",
    "\n",
    "ravdess='C:\\\\Users\\\\asus\\\\Speech Emotion Recognition\\\\RAVDESS Dataset'\n",
    "actorsfolder=os.listdir(ravdess)\n",
    "for actors in actorsfolder:\n",
    "    actor=os.listdir(ravdess + '\\\\' + actors)\n",
    "    for file in actor:\n",
    "        part=file.split('-')\n",
    "        fileEmotion.append(int(part[2]))\n",
    "        filePath.append(ravdess + '\\\\' + actors + '\\\\' + file)\n",
    "\n",
    "#fileEmotion\n",
    "#filePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe663ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(fileEmotion, columns=['Emotions'])\n",
    "df.replace([1,2,3,4,5,6,7,8],['neutral','calm','happy','sad','angry','fearful','disgust','surprised'], inplace=True)\n",
    "df.insert(1,'FilePath',filePath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b694a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Ravdess Summary.csv\", index=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Ravdess Summary.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150972c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing a countplot\n",
    "import seaborn as sns\n",
    "sns.countplot(df.Emotions)\n",
    "plt.xlabel('Emotions',size=10)\n",
    "plt.ylabel('Count',size=10)\n",
    "plt.title('Count of Emotions',size=16)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a246d39",
   "metadata": {},
   "source": [
    "### Wave-plot of audiofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating waveplot \n",
    "def createWave(data, sr, x):\n",
    "    img=librosa.display.waveshow(data, sr=sr)\n",
    "    plt.title('Waveplot for {} emotion'.format(x), size=16)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2382c",
   "metadata": {},
   "source": [
    "### Spectrogram of audiofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating spectogram\n",
    "def createSpectrogram(data, sr, x):\n",
    "    s=np.abs(librosa.stft(data))\n",
    "    S=librosa.amplitude_to_db(s, ref=np.max)\n",
    "    librosa.display.specshow(S, sr=sr, x_axis='time', y_axis='linear')\n",
    "    plt.title('Spectrogram for {} emotion'.format(x), size=16)\n",
    "    plt.colorbar(format='%+2.f dB')\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81ec4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drawing waveplot and spectrogram for angry emotion\n",
    "\n",
    "emotion='angry'\n",
    "path=np.array(df.FilePath[df.Emotions==emotion])[0]\n",
    "file, sr=librosa.load(path)\n",
    "createWave(file, sr, emotion)\n",
    "createSpectrogram(file, sr, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing waveplot and spectrogram for disgust emotion\n",
    "\n",
    "emotion='disgust'\n",
    "path1=np.array(df.FilePath[df.Emotions==emotion])[1]\n",
    "file, sr=librosa.load(path1)\n",
    "createWave(file, sr, emotion)\n",
    "createSpectrogram(file, sr, emotion)\n",
    "Audio(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e653b",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sr=librosa.load(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise\n",
    "\n",
    "def add_noise(data):\n",
    "    x=data.std()\n",
    "    noise=np.random.normal(0, x, data.size)\n",
    "    aug_data=data + noise*0.2\n",
    "    return aug_data\n",
    "\n",
    "noise_data=add_noise(data)\n",
    "createWave(noise_data, sr, emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "sf.write('added_noise.wav', noise_data, sr)\n",
    "Audio('added_noise.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Stretch\n",
    "\n",
    "def stretch(data):\n",
    "    return librosa.effects.time_stretch(data, rate=0.8)\n",
    "\n",
    "stretch_data=stretch(data)\n",
    "\n",
    "sf.write('stretch_time.wav', stretch_data, sr)\n",
    "createWave(stretch_data, sr, emotion)\n",
    "Audio('stretch_time.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch-Shift\n",
    "\n",
    "def pitch(data):\n",
    "    return librosa.effects.pitch_shift(data, sr=sr, n_steps=0.7)\n",
    "\n",
    "pitchShift_data=pitch(data)\n",
    "\n",
    "sf.write('shift_pitch.wav', pitchShift_data, sr)\n",
    "createWave(pitchShift_data, sr, emotion)\n",
    "Audio('shift_pitch.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift Data\n",
    "\n",
    "def shift(data):\n",
    "    shiftRange=int(np.random.uniform(low=-5, high=5)*1000)\n",
    "    return np.roll(data, shiftRange)\n",
    "\n",
    "shift_data=shift(data)\n",
    "\n",
    "sf.write('shift_data.wav', shift_data, sr)\n",
    "createWave(shift_data, sr, emotion)\n",
    "Audio('shift_data.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb79b3",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting 3 important features i.e. mfcc, chroma, mel-spectrogram\n",
    "\n",
    "def extractFeature(path, mfcc, chroma, mel):\n",
    "    data, sr=librosa.load(path)\n",
    "    \n",
    "    res=np.array([])\n",
    "    \n",
    "    if mfcc:\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40).T, axis=0)\n",
    "        res=np.hstack((res, mfccs))\n",
    "    \n",
    "    if chroma:\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=np.abs(librosa.stft(data)), sr=sr).T, axis=0)\n",
    "        res=np.hstack((res, chroma))\n",
    "    \n",
    "    if mel:\n",
    "        mel=np.mean(librosa.feature.melspectrogram(data, sr=sr).T, axis=0)\n",
    "        res=np.hstack((res, mel))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f36ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "\n",
    "ravdess='C:\\\\Users\\\\asus\\\\Speech Emotion Recognition\\\\RAVDESS Dataset'\n",
    "actorsfolder=os.listdir(ravdess)\n",
    "for actors in actorsfolder:\n",
    "    actor=os.listdir(ravdess + '\\\\' + actors)\n",
    "    for file in actor:\n",
    "        path=(ravdess + '\\\\' + actors + '\\\\' + file)\n",
    "        features=extractFeature(path, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(features)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ef576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=df.FilePath.apply(lambda x: extractFeature(x, mfcc=True, chroma=True, mel=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[i for i in df.FilePath]\n",
    "for path in paths:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c24814",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving featues array in a file to save time \n",
    "file=open('Features_mlp_ravdess', 'wb')\n",
    "np.save(file, x)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loding the features file\n",
    "file=open('Features_mlp_ravdess', 'rb')\n",
    "features=np.load(file)\n",
    "type(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8296b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, y, test_size=0.25, random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features extracted\n",
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96273e7e",
   "metadata": {},
   "source": [
    "### Initialising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56776029",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(500,),learning_rate='adaptive', max_iter=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c935d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f482c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "#joblib.dump(model, 'model.pkl')\n",
    "#clf=joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using model\n",
    "exp_y = y_test\n",
    "pred_y = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59195ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(exp_y, pred_y)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb130f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(exp_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e623401",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=pred_y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd828a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed613af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06a32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
